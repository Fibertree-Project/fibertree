{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Graph Scheduling Operations\n",
    "\n",
    "Examples of scheduling directives used in graph (and other) processing\n",
    "\n",
    "First, include some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run boilerplate code to set up environment\n",
    "\n",
    "%run prelude.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Function to create graph inputs\n",
    "#\n",
    "\n",
    "def create_inputs(display=True):\n",
    "    \n",
    "    # Adjacency matrix - Ranks \"S\" (source) and \"D\" (destination)\n",
    "\n",
    "    a = Tensor.fromUncompressed([ \"S\", \"D\"],\n",
    "                                [ [ 0, 1, 1, 0, 0, 0, 0, 1 ],\n",
    "                                  [ 0, 0, 1, 1, 0, 0, 1, 0 ],\n",
    "                                  [ 0, 0, 0, 1, 1, 0, 0, 0 ],\n",
    "                                  [ 0, 0, 0, 0, 1, 1, 0, 0 ],\n",
    "                                  [ 1, 0, 0, 0, 0, 1, 0, 0 ],\n",
    "                                  [ 0, 1, 0, 0, 0, 0, 1, 0 ],\n",
    "                                  [ 0, 0, 0, 1, 0, 1, 0, 0 ],\n",
    "                                  [ 1, 1, 0, 0, 0, 1, 0, 0 ] ])\n",
    "\n",
    "\n",
    "    print(\"Adjacency Matrix\")\n",
    "    displayTensor(a)\n",
    "\n",
    "    return (a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniform coordinate space tiling of two ranks (edge blocking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create inputs\n",
    "\n",
    "a = create_inputs()\n",
    "\n",
    "a_s = a.getRoot()\n",
    "\n",
    "print(\"Graph\")\n",
    "displayGraph(a_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split top rank(source rows) uniformly in coordinate space creating new rank (source tiles)\n",
    "\n",
    "tile_size = 4\n",
    "\n",
    "a_s = a_s.splitUniform(tile_size)\n",
    "\n",
    "print(f\"Source nodes split uniformly by {tile_size} coordinates\")\n",
    "displayTensor(a_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split thrid rank (destination columns) in coordinate space creating new rank (destination tiles)\n",
    "\n",
    "a_s.splitUniformBelow(4, depth=1)\n",
    "\n",
    "print(f\"Destination nodes split uniformly by {tile_size} coordinates\")\n",
    "displayTensor(a_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap second rank (source rows) with third rank (destination tiles)\n",
    "# Result is:\n",
    "#   - Source tiles\n",
    "#   - Destination tiles\n",
    "#   - Source rows\n",
    "#   - Destination columns\n",
    "\n",
    "a_s.swapRanksBelow()\n",
    "\n",
    "print(f\"Partitioned into {tile_size}x{tile_size} tiles\")\n",
    "displayTensor(a_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the graph for each tile - source nodes and destination nodes each in their own coordinate space tile\n",
    "\n",
    "for st, a_dt in a_s:\n",
    "    for dt, tile in a_dt:\n",
    "        print(f\"Graph tile ({st}, {dt})\")\n",
    "        displayGraph(tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top rank decreasing cluster size partitioning (ETWC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inputs\n",
    "\n",
    "a = create_inputs()\n",
    "\n",
    "a_s = a.getRoot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 3's then the remainder by 1s\n",
    "\n",
    "cluster_sizes = [3, 1]\n",
    "\n",
    "partition_counts = []\n",
    "remainder_sizes = []\n",
    "total_sizes = []\n",
    "\n",
    "remaining = len(a_s)\n",
    "\n",
    "for size in cluster_sizes:\n",
    "    # Number of clusters in this partition\n",
    "    partition_counts.append(remaining // size)\n",
    "\n",
    "    # Total number of coordinates for this cluster size\n",
    "    total_sizes.append(partition_counts[-1] * size)\n",
    "\n",
    "    # Number of coordinates left after this cluster size\n",
    "    remainder_sizes.append(remaining % size)\n",
    "    \n",
    "    # Number of unallocated coordinates\n",
    "    remaining = remainder_sizes[-1]\n",
    "\n",
    "print(f\"Cluster sizes = {cluster_sizes}\")\n",
    "print(f\"Partition counts = {partition_counts}\")\n",
    "print(f\"Total sizes = {total_sizes}\")\n",
    "\n",
    "splits = []\n",
    "\n",
    "for size, count in zip(cluster_sizes, partition_counts):\n",
    "    splits += [size]*count\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Splits = {splits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split according to splits\n",
    "\n",
    "a_s_split = a_s.splitUnEqual(splits)\n",
    "\n",
    "print(f\"Graph split into groups of sizes of {splits}\")\n",
    "displayTensor(a_s_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra optional step in which cluster sizes are divided at a new rank\n",
    "\n",
    "a_s_split2 = a_s_split.splitUnEqual(partition_counts)\n",
    "displayTensor(a_s_split2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the graph for each cluster\n",
    "\n",
    "for st, a_dt in a_s_split2:\n",
    "    for dt, tile in a_dt:\n",
    "        print(f\"Graph tile ({st}, {dt}) - has {len(tile)} source nodes\")\n",
    "        displayGraph(tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split first rank by position. Flatten and split by position again (WC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inputs\n",
    "\n",
    "a = create_inputs()\n",
    "\n",
    "a_s = a.getRoot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s_partitions = 3\n",
    "d_per_group = 4\n",
    "\n",
    "a_s_split = a_s.splitEqual(s_partitions)\n",
    "\n",
    "print(f\"Graph split into {s_partitions} source nodes per partition\")\n",
    "displayTensor(a_s_split)\n",
    "\n",
    "a_s_split.flattenRanksBelow()\n",
    "a_s_split.splitEqualBelow(d_per_group)\n",
    "a_s_split.unflattenRanksBelow(depth=1)\n",
    "\n",
    "print(\"Graph split again with {d_per_group} destinations per group\")\n",
    "displayTensor(a_s_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the graph for each group - each group should have 4 edges\n",
    "\n",
    "for st, a_dt in a_s_split:\n",
    "    for dt, tile in a_dt:\n",
    "        print(f\"Graph tile ({st}, {dt})\")\n",
    "        displayGraph(tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degree based splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inputs\n",
    "\n",
    "a = create_inputs()\n",
    "\n",
    "a_s = a.getRoot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2\n",
    "\n",
    "a_s_big = Fiber()\n",
    "a_s_small = Fiber()\n",
    "ad = Fiber([0, 1], [a_s_big, a_s_small])\n",
    "\n",
    "for s, (a_d) in a_s:\n",
    "    if len(a_d) > threshold:\n",
    "        print(f\"Adding big {s}, {a_d}\")\n",
    "        a_s_big.append(s, a_d)\n",
    "    else:\n",
    "        print(f\"Adding small {s}, {a_d}\")\n",
    "        a_s_small.append(s, a_d)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Graph split into nodes with > {threshold} destinations and <= {threshold} destinations\")\n",
    "displayTensor(ad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the graph for group - buckets should have >2 or <=2 edges\n",
    "\n",
    "for bucket, tile in ad:\n",
    "    print(f\"Graph bucket: {bucket}\")\n",
    "    displayGraph(tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing area\n",
    "\n",
    "For running alternative algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
