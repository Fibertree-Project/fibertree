{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Position space tiling of A-stationary row-major spMspM\n",
    "\n",
    "When using an m/k/n dataflow for matrix multiply there is an interesting opportunity for position-space tiling in the k rank of the A matrix. This notebook illustrates two examples of such tiling. \n",
    "\n",
    "First, include some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run boilerplate code to set up environment\n",
    "\n",
    "%run ../prelude.py --style=tree --animation=movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor(os.path.join(data_dir, \"sparse-matrix-a.yaml\"))\n",
    "b = Tensor(os.path.join(data_dir, \"sparse-matrix-b.yaml\"))\n",
    "\n",
    "# Transpose the \"a\" matrix as desired by the outer product traveral order\n",
    "at = Tensor.fromFiber([\"K\", \"M\"], a.getRoot().swapRanks())\n",
    "\n",
    "print(\"Input A\")\n",
    "displayTensor(a.setColor(\"blue\"))\n",
    "\n",
    "#print(\"Input A - transposed\")\n",
    "#displayTensor(at.setColor(\"blue\"))\n",
    "\n",
    "print(\"Input B\")\n",
    "displayTensor(b.setColor(\"green\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary position-space tiling\n",
    "\n",
    "Split the A matrix in position space in the K-rank and then swap ranks. This results in a position-space tiling of the A matrix so that the work can be divided temporarly (or spatially) between the top rank tiles. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "displayTensor(a)\n",
    "\n",
    "a1 = a.splitEqual(3, depth=1).updateCoords(lambda n, c, p: n, depth=1)\n",
    "displayTensor(a1)\n",
    "\n",
    "a2 = a1.swapRanks()\n",
    "displayTensor(a2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-stationary/row-major spMspM\n",
    "\n",
    "This dataflow traverses the position-space tiled **A** tensor\n",
    "\n",
    "Observations:\n",
    "\n",
    "- K-rank coordinates in **B** matrix fibers are reused when computing different **A** matrix tiles. This would not happen if the positioning was in coordinate-space.\n",
    "\n",
    "- Fewer **Z** tensor values are touched while working on the larger coordinate (right most) K.1-rank tiles. This is part of the motivation for the reversed K.1-rank fiber traversal in [Sparch](./sparch.ipnb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Tensor(rank_ids=[\"M\", \"N\"])\n",
    "z.setName(\"Z\")\n",
    "\n",
    "a_k1 = a2.getRoot()\n",
    "b_k = b.getRoot()\n",
    "z_m = z.getRoot()\n",
    "\n",
    "canvas = createCanvas(a2, b, z)\n",
    "\n",
    "for k1, a_m in a_k1:\n",
    "    for m, (z_n, a_k) in z_m << a_m:\n",
    "        for k, (a_val, b_n) in a_k & b_k:\n",
    "            for n, (z_ref, b_val) in z_n << b_n:\n",
    "                z_ref += a_val * b_val\n",
    "                addFrame(canvas, (k1, m, k), (k, n), (m, n))\n",
    "\n",
    "displayTensor(z)\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tile in position space and merge top ranks\n",
    "\n",
    "Given that position-space tiling of the K-rank does not partition accesses of the **B** matrix, one can flatten the elements of the tiles into a single rank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayTensor(a)\n",
    "\n",
    "a3 = a.splitEqual(3, depth=1)\n",
    "displayTensor(a3)\n",
    "\n",
    "a4 = a3.flattenRanks()\n",
    "displayTensor(a4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-stationary/row-major spMspM\n",
    "\n",
    "This dataflow traverses the flattened M/K1 ranks, which could be reordered (see [dynamic reordering notebook](./reordered-spMspM.ipynb)) to optimize the pattern of B tensor accesses, e.g., for better cache locality. However, that would result in more discordant access to the M-rank of **Z**. It also means that if all of **Z** cannot be buffered, then multiple shards of N-rank fibers in **Z** would be created and need to be reduced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Tensor(rank_ids=[\"M\", \"N\"])\n",
    "z.setName(\"Z\")\n",
    "\n",
    "a_m = a4.getRoot()\n",
    "b_k = b.getRoot()\n",
    "z_m = z.getRoot()\n",
    "\n",
    "canvas = createCanvas(a4, b, z)\n",
    "\n",
    "for (m, k1), a_k in a_m:\n",
    "    z_n = z_m.getPayloadRef(m)\n",
    "    for k, (a_val, b_n) in a_k & b_k:\n",
    "        for n, (z_ref, b_val) in z_n << b_n:\n",
    "            z_ref += a_val * b_val\n",
    "            addFrame(canvas, [((m, k1), k)], [(k, n)], [(m, n)])\n",
    "\n",
    "displayTensor(z)\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing area\n",
    "\n",
    "For running alternative algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
