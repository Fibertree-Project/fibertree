{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Update batching\n",
    "\n",
    "This notebook explores the concept of update batching using a very simple example\n",
    "\n",
    "First, include some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run boilerplate code to set up environment\n",
    "\n",
    "%run ../prelude.py --style=tree --animation=movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a simple graph\n",
    "\n",
    "The graph consists of a vertex vector (__vtx__) and an adjacency matrix (__g_SD__). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 10\n",
    "D = S\n",
    "\n",
    "vtx = Tensor.fromRandom([\"S\"], [S], (1.0,), 9, seed=10)\n",
    "#vtx = Tensor.fromUncompressed([\"S\"], [1]*S)\n",
    "vtx.setMutable(True).setColor(\"blue\")\n",
    "vtx.setName(\"vertices\")\n",
    "\n",
    "g_SD = Tensor.fromRandom([\"S\", \"D\"], [S, D], (1.0, 0.28), 1, seed=100)\n",
    "g_SD.setMutable(True).setColor(\"green\")\n",
    "g_SD.setName(\"graph-SD\")\n",
    "\n",
    "displayTensor(vtx)\n",
    "displayTensor(g_SD)\n",
    "                         \n",
    "print(\"Graph\")\n",
    "displayGraph(g_SD.getRoot())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic algorithm - Source Stationary\n",
    "\n",
    "In this notebook, we use a simple example where we update the value of each vertex (in __vtx__) with the sum of the values of all its incoming neighbor vertices. Following is a source-stationary (push) dataflow via a concordant traversal through the adjacency matrix (__g_SD__) to do that. Note the widely scattered writes to the new vertices (in __vtx_new__), i.e., a discordant traversal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtx_new = Tensor(rank_ids=[\"S\"])\n",
    "vtx_new.setColor(\"blue\")\n",
    "vtx_new.setName(\"vertices_new\")\n",
    "\n",
    "vtx_s = vtx.getRoot()\n",
    "g_SD_s = g_SD.getRoot()\n",
    "vtx_new_d = vtx_new.getRoot()\n",
    "\n",
    "canvas = createCanvas(vtx, g_SD, vtx_new)\n",
    "\n",
    "for s, (vtx_val, g_SD_d) in vtx_s & g_SD_s:\n",
    "    for d, (vtx_new_ref, _) in vtx_new_d << g_SD_d:\n",
    "        vtx_new_ref += vtx_val\n",
    "        addFrame(canvas, (s, ), (s, d), (d,))\n",
    "\n",
    "displayTensor(vtx_new)\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic algorithm - Destination stationary\n",
    "\n",
    "Just for the record, here is the same algorithm in a destination stationary (pull) form. To faciliate concordant traversal of the adjacency matrix, we create a rank swapped version (__g_DS__). Not the discordant traversal of the original vertex matrix (__vtx__) for this dataflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create destination-to-source adjacency matrix\n",
    "\n",
    "g_DS = g_SD.swapRanks()\n",
    "g_DS.setName(\"graph-DS\")\n",
    "\n",
    "displayTensor(g_DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtx_new = Tensor(rank_ids=[\"S\"])\n",
    "vtx_new.setColor(\"blue\")\n",
    "vtx_new.setName(\"vertices_new\")\n",
    "\n",
    "vtx_s = vtx.getRoot()\n",
    "g_DS_d = g_DS.getRoot()\n",
    "vtx_new_d = vtx_new.getRoot()\n",
    "\n",
    "canvas = createCanvas(vtx, g_DS, vtx_new)\n",
    "\n",
    "for d, (vtx_new_ref, g_DS_s) in vtx_new_d << g_DS_d:\n",
    "    for s, (vtx_val, _) in vtx_s & g_DS_s:\n",
    "        \n",
    "        vtx_new_ref += vtx_val\n",
    "        addFrame(canvas, (s, ), (d, s), (d,))\n",
    "\n",
    "displayTensor(vtx_new)\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions used in the following steps\n",
    "\n",
    "To generalize the implementation of algorithms that use update batching, the dataflows call these functions to calculate a value to be reduced (__generateShard()__) and a value to do a final update of each vertex (__updateValue()__). The very simple functions below implement the simple algorithm described above, and could be replaced to implement different algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "# The function for the first step\n",
    "#\n",
    "def generateShard(vtx_val):\n",
    "    \"\"\"Create a value to be reduced later\"\"\"\n",
    "    \n",
    "    return vtx_val\n",
    "\n",
    "#\n",
    "# The function for the final step\n",
    "#\n",
    "\n",
    "def updateValue(vtx_val_old, vtx_val_new):\n",
    "    \"\"\"Update the vertex value\"\"\"\n",
    "    \n",
    "    return vtx_val_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Update batch sequence\n",
    "\n",
    "Do a (concordant) source-stationary traversal of the vertices (__vtx__) and adjacency matrix (__g_SD__), but instead of trying to directly update each destination vertex (a discordant traversal), just log the destination vertex id and source vertex value (as a tuple) in a rank-2 tensor (__bins__). When logging, select a bin id (top rank coordinate) by a partitioning of the destination vertex ids (e.g., divide destination vertex id (coordinate) by 2). Note that the additions to the fibers in the lower rank of __bins__ is always just at the end of the fibers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coordinates_per_bin = 2\n",
    "\n",
    "bins = Tensor(rank_ids=[\"B\", \"N\"])\n",
    "bins.setColor(\"purple\").setName(\"bins\")\n",
    "\n",
    "vtx_s = vtx.getRoot()\n",
    "g_SD_s = g_SD.getRoot()\n",
    "bins_b = bins.getRoot()\n",
    "\n",
    "canvas = createCanvas(vtx, g_SD, bins)\n",
    "n = 0\n",
    "\n",
    "for s, (vtx_val, g_SD_d) in vtx_s & g_SD_s:\n",
    "    for d, _ in g_SD_d:\n",
    "        n += 1\n",
    "        \n",
    "        b = d//coordinates_per_bin\n",
    "        bins_n = bins_b.getPayloadRef(b)\n",
    "        \n",
    "        bins_n.append(n, (d,  generateShard(vtx_val)))\n",
    "        addFrame(canvas, [(s, )], [(s, d)], [(b, n)])\n",
    "        \n",
    "displayTensor(bins)\n",
    "displayCanvas(canvas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2  - Replay the log\n",
    "\n",
    "Do a concordant traversal of all the elements of the log tensor (__bins__) and reduce on a per vertex id basis using the logged vertex id and value into a new vertex vector (__vtx_new__). Although the traversal of the new vertex vector will be discordant, while processing each bin (top rank coordinate of __bins__) the range of active source vertex ids (coordinates) will be quite small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtx_new = Tensor(rank_ids=[\"S\"])\n",
    "vtx_new.setColor(\"blue\")\n",
    "vtx_new.setName(\"vertices_new\")\n",
    "\n",
    "bins_b = bins.getRoot()\n",
    "vtx_new_s = vtx_new.getRoot()\n",
    "\n",
    "canvas = createCanvas(bins, vtx_new)\n",
    "\n",
    "for b, bins_n in bins_b:\n",
    "    for n, (s, val) in bins_n:\n",
    "        vtx_new_s = vtx_new.getPayloadRef(s)\n",
    "        vtx_new_s += val\n",
    "        addFrame(canvas, (b, n), (s,))\n",
    "        \n",
    "        \n",
    "displayTensor(vtx_new)\n",
    "displayCanvas(canvas)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2  - Replay the log - with shortcuts\n",
    "\n",
    "Given the nice pattern of the values returned by the getPayloadRef() method call exhibited by the above dataflow, one can use a shortcut to optimize the search for the desired coordinate in the __getPayloadRef()__ call by using the \"start_pos\" shortcut. The following cell displays a control to enable or disable the use of the shortcut for the following log replay dataflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createEnableControl(\"Use shortcut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "vtx_new = Tensor(rank_ids=[\"S\"])\n",
    "vtx_new.setColor(\"blue\")\n",
    "vtx_new.setName(\"vertices_new\")\n",
    "\n",
    "bins_b = bins.getRoot()\n",
    "vtx_new_s = vtx_new.getRoot()\n",
    "\n",
    "canvas = createCanvas(bins, vtx_new)\n",
    "\n",
    "next_start_pos = 0\n",
    "\n",
    "for b, bins_n in bins_b:\n",
    "    start_pos = next_start_pos\n",
    "    \n",
    "    for n, (s, val) in bins_n:\n",
    "        vtx_new_ref = vtx_new_s.getPayloadRef(s, start_pos=start_pos)\n",
    "        if enable[\"Use shortcut\"]:\n",
    "            next_start_pos = max(next_start_pos, vtx_new_s.getSavedPos())\n",
    "        \n",
    "        vtx_new_ref += val\n",
    "        addFrame(canvas, (b, n), (s,))\n",
    "        \n",
    "(n, distance) = vtx_new_s.getSavedPosStats()\n",
    "print(f\"Average search distance = {distance/n:4.2f}\")\n",
    "      \n",
    "displayTensor(vtx_new)\n",
    "displayCanvas(canvas)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - New vertex value mapping\n",
    "\n",
    "Sometimes there is an algorithmic step to update the orginal vertex values with a function of the original and new vertex values. Note that for iterative algorithms this step can be fused with the next update batch sequence (step 1). If processed separately it is a simple (concordant) traveral of the original and new vertex values. Note, we copy the orginal vertex tensor (__vtx__) into a new tensor (__vtx_copy__) to hold the updated vertices to avoid clobering the original vertex tensor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "vtx_copy = copy.deepcopy(vtx)\n",
    "\n",
    "vtx_s = vtx_copy.getRoot()\n",
    "vtx_new_s = vtx_new.getRoot()\n",
    "\n",
    "canvas = createCanvas(vtx_new, vtx_copy)\n",
    "\n",
    "for s, (vtx_ref, vtx_new_val) in vtx_s << vtx_new_s:\n",
    "    vtx_ref <<= updateValue(vtx_ref, vtx_new_val)\n",
    "    addFrame(canvas, (s,), (s,))\n",
    "\n",
    "displayTensor(vtx_copy)\n",
    "displayCanvas(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing area\n",
    "\n",
    "For running alternative algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
